The problems are taken from the Assignments given by <b>Professor Zhang</b> while teaching <b>Introduction to Machine Learning</b> at University of Illinois at Chicago.

The book which I used to study for this course is <b>Introduction to Machine Learning, Third Edition by Ethem Alpaydin</b>.

<b>Linear Regression</b>:
We can see implementation of Linear Regression using numpy in this Lab.
We can also see the effects of Learning Rate and Number of Iteration on the MSE.
<img width="765" alt="image" src="https://github.com/sankalprane/Intro-to-Machine-Learning/assets/73281026/5be30168-47a8-4032-aaf8-6cca590e83b8">

<b>KNN</b>:
In this Lab we can see the implementation of KNN for Optical Character Recognition for the MNIST dataset.

<b>Cross Validation</b>:
In this Lab we can see the implementation of K-fold Cross Validation.
The below image shows the change in error rate with the change in number of folds(k value)
<img width="752" alt="image" src="https://github.com/sankalprane/Intro-to-Machine-Learning/assets/73281026/2f44d910-bcba-4f90-9d40-097d61129027">

<b>Multivariate Methods</b>:
In the image shown below we can see the contours for probabilty density function depending on the covariance matrix.
<img width="696" alt="image" src="https://github.com/sankalprane/Intro-to-Machine-Learning/assets/73281026/bdfed12b-0c31-4c1a-bc25-ad146593dfcf">

<b>Naive Bayes Classification</b>:
In this Lab we can see the implementation of spam detection using Naive Bayes Classification. Here we are using smoothing to deal with words that we have not seen in the past.

<b>Decision Tree</b>:
In this Lab we make use of Gini Index as the cost function to evaluate the splits while building the tree.

<b>Logistic Regression</b>:
In this Lab we have implemented Logistic Regression for multiclass classification for load_digits dataset in sklearn.
